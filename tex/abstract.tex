

With the rapid rise in popularity of wearable devices like smartwatches, health monitoring applications are gaining traction due to their ability to monitor a range of health metrics, such as sleep patterns, heart rate, and physical activity. These applications commonly utilize photoplethysmograph sensors to assess various elements of an individual's health and wellness. Photoplethysmography is a non-invasive and economical optical method that detects variations in blood volume within the microvascular network of tissues, providing continuous measurements of physiological changes over time. Examining photoplethysmograph signals allows for the extraction of valuable insights regarding cardiovascular health and various physiological metrics, including heart rate variability, peripheral oxygen saturation, and sleep patterns. However, despite its benefits, photoplethysmography has a major limitation: it is particularly susceptible to motion artifacts and environmental interferences. These issues can greatly impair the effectiveness of photoplethysmography-based applications, especially when capturing photoplethysmograph signals using wearable devices. Therefore, to achieve accurate measurements, it is crucial to have appropriate signals that are sampled with high reliability.

In this context, assessing the signal quality is essential for enabling health monitoring applications, as high signal quality is crucial for reliably assessing a patientâ€™s medical condition. To achieve this, machine learning algorithms can be applied. This work presents an innovative method for assessing the quality of photoplethysmograph signals, accomplished through a fusion of signal projections and computer vision techniques. To be more precise, the one-dimensional photoplethysmograph signal is projected to a set of bidimensional representations. This can be accomplished using time series imaging techniques, such as \acrlong{GAF}, \acrlong{MTF} and \acrlong{RP}, and by aggregating their results, which is referred to as `Projection Mix'. After pre-processing the \acrlong	{BUTPPG} dataset into these images, various deep neural networks are trained and tested, with hyperparameters selected through heuristic searching. The results indicate that the \acrlong{RP} and Projection Mix generally outperformed \acrlong{GAF} and \acrlong{MTF} across most compute vision models. Additionally, projection-based methods achieved results comparable to 1D time series classifiers. For instance, the combination of Wide ResNet with Projection Mix achieved a K-Fold mean Cohen Kappa score of 95.5\% (rescaled from $[-1,1]$ to $[0,1]$) with a standard deviation of 0.101. An implementation of the method and experiments described in this thesis can be found at \url{https://gitlab.com/lisa-unb/projection-based-biological-signal-processing}.
