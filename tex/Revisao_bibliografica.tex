
% Supõe-se que, na introdução, tenha sido posto a definição do problema de SQA como a necessidade de garantir um sinal de boa qualidade, seja para humanos não cometerem enganos, seja para modelos preditivos serem capazes de estimar com acurácia.

In this chapter I present the state of the literature of the \acrlong{SQA} of cardiological signals problem, focused on my work scope.

\section{The Feature Extraction Method}
\label{sec:feature}

To give a proper \acrshort{SQI} for the \acrshort{SQA}, we need to extract proper features from the input signal. For this purpose, researchers proposed several features to be extracted. For instance, \citeauthor{review-1} poses the measurement of a \acrshort{SQI} through the application of the Dynamic Time Warping techinique \cite{review-1}. It finds the optimal path cost on a distance matrix which encodes the differences between each pair of points of the input and a template, reference of a good signal. \citeauthor{review-1} added this techinique \acrshort{SQI} to others and feeded them to a \acrshort{MLP} and to a self-made function, predicting a unique \acrshort{SQI}. Experiments on private annotations on the MIMIC II dataset resulted on the \acrshort{MLP} achieving the highest accuracy, 95.2\% \cite{review-1}. However, the result analysis does not isolate the proposed \acrshort{SQI}, not making clear how much it contributed to the final result if compared to the other \acrshort{SQI}s.      

Later, \citeauthor{review-2} proposed two features for the estimation of a classification \acrshort{SQI} of multi-channeled \acrshort{ECG}s. One feature consists of verifying if two energy-like indices, measured in deciBels, are within an admissible range. The first converts, for an instant of time, the signal amplitude to a logarithm scale. The second originates from a similar conversion, but by measuring the signal concavity. The other feature result from randomly chosing a target lead, feeding a \acrshort{FFNN} with array of derivatives of all leads to reconstruct the targeted lead and finally comparing the original target lead to its artificial version with correlation analysis. The researchers submited an entry on the CinC Challenge 2011 and achieved a accuracy of 93.60\%, overperforming many other approaches of its time.  

In 2017, \citeauthor{review-3} introduced a feature based on the extraction of the Heart Rate Variability of \acrshort{ECG} signals. The method decomposes this new signal into wavelets with different frequency ranges and calculates the each of them entropy, forming a feature vector. This vector feed a \acrshort{SVM}, which classifies the signal as acceptable or not. Tests on two private datasets obtained from different devices, indicates that the model is capable of reaching a high accuracies of 94\% and 96\%, respective to each dataset. While the model demonstrated adaptability to fit different devices, the researchers only compared the model to a simple QRS complex detector, making the results parallel to the state-of-art performance of its time.
	
One year later, \citeauthor{review-4} developed an image-based feature that measures the Structural Similarity Measure between the input plot image, containing each signal channel cartesian graph, and multiple template plot images of similar shape selected from the training dataset by using clustering analysis. Then, an experiment compared this \acrshort{SQI} to other existing ones testing on a private dataset, resulting in the proposed \acrshort{SQI} being the best with 93.1\% accuracy when using 380 template images. Additionally, experiments on the PhysioNet Challenge 2011 dataset, using template images from the private dataset, resulted in an accuracy of  82.5\%. While the accuracy in the public dataset was not high, the model presented a capacity of generalizing information of another dataset. Futhermore, the private dataset contained cases of arrhythmia, which was not the case for most of the previous studies that I mentioned. In the next section I will present this arrhythmia problem.  

\section{The Arythmia Problem}
\label{sec:arythmia}

The \acrfull{CA} is the presence of an anomalous cardiac rate, such as fast, slow or irregular \acrshort{HR} moments. Its cause is abnormalities in the cardiac nervous system. This medical condition is an obstacle in the design of \acrshort{SQI}, since, in contrast to arrhythmic individuals, normal cardiac signals are periodic. Some features assume that the signal is periodic, such as the naive \acrshort{HR} estimation based on QRS complexes. This assumption can result in signals with arrhythmia being reject as unreliable signals, leaving those special patients undiagnosed. \citeauthor{review-5} conducted experiments on a private dataset that contains cases of \acrfull{AF}, a type or arrhythmia \cite{review-5}. In this experiment, 40 features used in previous studies fed a \acrshort{SVM}, which achieved an average accuracy superior to 94\% \cite{review-5}. That accuracy was far higher than other existing methods, which the researchers also tested \cite{review-5}. Therefore, abbundant feeding a machine learning algorithm with features and training it on datasets with arrhytmia cases already present an improvement in the detection of those special cases.

In sequence, two studies adopted a similar approach to the one mentioned in the past paragraph to attack the arrhythmia problem. In the first study, \citeauthor{review-6} feeded several features to three classifiers: \acrshort{SVM}, \acrshort{K-NN} and Decision Tree \cite{review-6}. Similarly to the antecedent study, experiments on a private dataset demonstrated that the \acrshort{SVM} was the best of all classifiers and it obtained above 95\% suprassing the methods of other studies. The second study also included the \acrshort{SVM} method, but added to the experiment deep learning models \cite{review-7}. The study contemplated both 1d and 2d deep learning models, with the first recieving the raw signal and the second recieving its cartesian plot image. Experiments on private data with presence of \acrshort{AF} showed that the ResNet18 model was the best, with 98.5\% accuracy. That last study highlighted that deep learning models have the potential to supprass conventional methods even with the presence of arrythmic events. In the next section, I will further explore the use of deep learning in the literature.  

\section{The Deep Learning Approach}
\label{sec:deep_learning}

As already mentioned, \acrfull{DL} has the potential to achieve a higher accuracy than feature based models, even in the context of \acrshort{CA}. Differently of hand-crafted features, \acrshort{DL} automatically extract features from the input signal, creating models that are adaptable to different dataset training contexts. Additionally, a high quality dataset can provide resources for the \acrshort{DL} model to be robust to variations on the signal conditions. On the other hand, not only it creates a black-box that does not explain the reasons why the model atributed a certain \acrshort{SQI}, but also requires large ammounts of data to proper adjust the model parameters. Depite this, \acrshort{DL} are worth exploring since it can provide the accuracy and robustness that the medical applications require. 

In this context, several studies proposed the application of one-dimensional \acrshort{DL} models. For instance, \citeauthor{review-8} applied a self-designed \acrshort{CNN} to extract a binary \acrshort{SQI} \cite{review-8}. Tests on a private dataset with data of three devices lead to 85\% F1-score for the "Reliable" class. Alike, \citeauthor{review-9} employed a self-made \acrshort{CNN}, but examined the effect of transfer learning as well \cite{review-9}. They conducted the experiment on three private datasets. It beggan training the model mostly on one dataset, in which it achieved an accuracy of 99.8\%. Then, for each remaining database, they fine-tuned the the model with little training and tested on it. This procedure resulted on the 93\% and 81\% accuracies on the second and third datasets, respectively. Additionally, the model trained solely on the second database scored lower, 86\%. Those results indicate that not only we can use \acrshort{CNN} to achieve high accuracy but also we can transfer its learned features over different databases to improve its performance.

\section{The Time Series Imaging Techinique}
\label{sec:imaging}

\section{The Matrix Embedding Techinique}
\label{sec:matrix}
